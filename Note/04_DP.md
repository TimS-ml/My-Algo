# Dynamic Programming
    https://www.geeksforgeeks.org/dynamic-programming/
    https://en.wikipedia.org/wiki/Dynamic_programming
    https://labuladong.gitbook.io/algo-en/i.-dynamic-programming/analysisofdynamicprogramming

## Process
[1] Base State
[2] State Transfer Equation
[3] Initialize Conditions
[4] State Compression (optional)
[5] Terminate Conditions

draw the state tree can help you solve DP

Dynamic Programming is mainly an optimization over plain recursion
Wherever we see a recursive solution that has repeated calls for same inputs, we can optimize it using Dynamic Programming
The idea is to simply store the results of subproblems, so that we do not have to re-compute them when needed later 


## usage
- number of solutions / path
- optimal solutions
- can / cannot

init dp:
- dp = [0] + [float('inf')] * n
- collection.defaultdict (all 0)


## State Compression
LC062 sol3


## Memoization è®°å¿†åŒ– (Not Memorization)
    https://en.wikipedia.org/wiki/Memoization
Is an optimization technique used primarily to speed up computer programs by storing the results of expensive function calls and returning the cached result when the same inputs occur again


## Scrolling
lc070 sol4 (for simple dp)
If the current state is only related to the previous one, we can all simplify the space complexity by scrolling the array and variables


## Other
LC070
There are two typical implementations of Dynamic Programming approach: `bottom-to-top` (narrow sense dp) and `top-to-bottom` (memoization).

[1] Top-to-bottom Dynamic Programming is nothing else than ordinary recursion, enhanced with *memorizing the solutions for intermediate sub-problems*. 
When a given sub-problem arises second (third, fourth...) time, it is not solved from scratch, but instead the previously memorized solution is used right away. This technique is known under the name memoization (no 'r' before 'i').
This is actually what Fibonacci sequence is supposed to illustrate.

example: 
func c(n) -> return c(n-1) + c(n-2)
func c(n) -> subfunc calc cache(i) -> reutrn c(n-1)

[2] In Bottom-to-top Dynamic Programming the approach is also based on *storing sub-solutions* in memory, but they are solved in a different order (*from smaller to bigger*), and the resultant general structure of the algorithm is not recursive. LCS algorithm is a classic Bottom-to-top DP example.

func c(n) -> init dp[1], dp[2] -> return dp[n]
